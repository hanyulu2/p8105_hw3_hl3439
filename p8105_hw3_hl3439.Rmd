---
title: "Homework 3"
author: "Hanyu Lu"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document

---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Due date

Due: October 10 at 10:00pm. 

### Points

| Problem         | Points    |
|:--------------- |:--------- |
| Problem 0       | 20        |
| Problem 1       | --        |
| Problem 2       | 40        |
| Problem 3       | 40        |
| Optional survey | No points |


### Problem 0

This "problem" focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files. 


### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```

# Problem 2

```{r}
accel_df =
  read_csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_minute_o",
    values_to = "activity_counts"
  ) %>% 
  separate(activity_minute_o, into = c("activity", "activity_minute"), sep = 9) %>% 
  mutate(
    day = factor(day),
    day = ordered(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", 
"Friday", "Saturday", "Sunday")),
    activity_minute = as.double(activity_minute),
    weekday_vs_weekend = case_when(
      day == "Monday" ~ "Weekday",
      day == "Tuesday" ~ "Weekday",
      day == "Wednesday" ~ "Weekday",
      day == "Thursday" ~ "Weekday",
      day == "Friday" ~ "Weekday",
      day == "Saturday" ~ "Weekend",
      day == "Sunday" ~ "Weekend",
    )
  )

```

There are 6 variables in this dataset, including `r names(accel_df)`.  There are a total of `r nrow(accel_df)` observations.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(
    mean_day = mean(activity_counts),
  ) %>% 
  arrange(day) %>% 
  knitr::kable(digits = 1)
```

Tuesday and Wednesday have relatively stable activity counts, while Saturday and Sunday experience a decrease in activity counts.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  arrange(activity_minute) %>% 
  ggplot(aes(x = activity_minute, y = activity_counts, color = day)) + 
    geom_line(alpha = 0.3) +
    geom_smooth(se = FALSE) +
  scale_x_discrete(
    breaks = c(0, 720, 1440), 
    labels = c(0, 12, 24))

```

In general, this patient has a decreasing trend in total activities.  This patiennt tends to do more activities at noon in Sunday, and at night in weekdays.

# Problem 3

```{r}
library(p8105.datasets)
data("ny_noaa")
```

```{r}
ny_noaa %>% 
  mutate(
    year = lubridate::year(date), 
    month = lubridate::month(date), 
    day = lubridate::day(date),
    tmax = as.numeric(tmax),
    tmax = tmax/10,
    tmin = as.numeric(tmin),
    tmin = tmin/10
  ) %>% 
  select(-date)

ny_noaa %>% 
	count(snow) %>% 
	arrange(desc(n))
  
```

I convert tenths of Celcius degree to Celcius degree to make it easier to understand.The most commonly observed value for snowfall is 0 because New York has a higher probability of not snowing all over the year.

```{r}
ny_noaa %>% 
  mutate(
    year = lubridate::year(date), 
    month = lubridate::month(date), 
    day = lubridate::day(date),
    tmax = as.numeric(tmax),
    tmax = tmax/10,
    tmin = as.numeric(tmin),
    tmin = tmin/10
  ) %>% 
  select(-date) %>% 
	filter(month == 7 | month == 1) %>% 
	group_by(id, month, year) %>% 
  summarize (
    mean_tmax = mean(tmax, na.rm=TRUE)
  ) %>% 
  ggplot(aes(x = year, y = mean_tmax, color = id)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(se = FALSE, color = 100) +
  facet_grid(. ~ month) +
  theme(legend.position = "none")
```

The temperature of January is around 0 degrees C with fluctuations, while temperature of July is around 25 degrees C with smoother line.  There are extremely cold Januarys in 1982 and 2005, and an unusually cool July in 1988.



